Elastic Cache는 분산 인 메모리 캐시(In-Memory Cache)를 손쉽게 생성하고 확장할   
수 있는 서비스이다.   

> #### 프리티어에서 사용 가능   
> ElasticCache는 프리티어에서 무료로 사용할 수 있다. 2014년 4월 기준으로 매달   
> 마이크로 캐시 노드 750시간을 무료로 사용할 수 있다.   

ElasticCache를 사용해야 하는 이유는 성능과 편의성, 분산 캐시 환경 구축에 필요한   
비용을 절감하는데 있다. 읽기 중심의 서비스(소셜 네트워크, 게임, 추천 엔징 등)를  
제공해야 하는 환경, 고속으로 데이터를 분석해야 하는 환경에 적합하다. 그리고  
데이터베이스의 부하를 줄이고자 할 때, 대용량 분산 [캐시](https://mangkyu.tistory.com/69) 환경을 자체적으로 운영  
하기에는 부담이 있을 때 유용하다.   
  
인 메모리 캐시는 모든 데이터를 메모리(RAM)에만 올려놓고 사용하는 데이터베이스의  
일종이다. 일반적인 데이터베이스(RDBMS)는 디스크(HDD, SSD)에 데이터를 영구적으로   
저장해놓고, 필요한 데이터만 메모리에 읽어서 사용한다. 이 것이 인 메모리 캐시와  
데이터베이스의 가장 큰 차이점이다.   
<img src="https://user-images.githubusercontent.com/33191974/156914887-0936891c-08bf-4ef5-8daf-e6b0ba588218.png" width="50%" height="50%"/>    
인 메모리 캐시는 모든 데이터를 메모리에 올려놓는 것이 특징이다. 디스크에 접근하지   
않고 메모리로만 모든 처리를 하기 때문에 데이터 저장 및 검색속도가 매우 빠르다.   
단 데이터는 딱 메모리 크기(운영체제 사용량 제외)까지만 저장할 수 있다. 또한,  
메모리에만 저장되어 있기 때문에 서버의 전원 공급이 중단되면 데이터는 소멸된다(  
이를 방지하기 위해서 데이터를 주기적으로 디스크에 백업하거나 데이터 로그를   
디스크에 남기는 방식이 있지만 데이터를 안전하게 유지하는 방법일수록 캐시의   
성능이 떨어진다).
  
서버 및 인터넷, 일반 컴퓨터 등에서 캐시라는 단어는 매우 자주 등장한다. Cloud  
Front에서도 파일을 빠르게 전송하기 위해, 세계 각지에 에지 로케이션을 두고  
파일을 캐시하며 웹 브라우저도 파일을 다시 받아오지 않기 위해 파일을 디스크에  
캐시한다. 인 메모리 캐시의 캐시도 비슷한 개념으로 쓰인다.   
  
보통 빠른 처리속도를 위해 데이터베이스에 저장된 데이터 중 쿼리 결과나 자주  
사용되는 데이터를 인 메모리 캐시에 임시로 저장한다. 즉 캐시(Cache)라는 단어   
뜻 그대로 인 메모리 캐시는 주로 임시 저장소로 사용된다(물론 인 메모리 캐시를  
메인 데이터 저장소로 사용할 수도 있다). 혹은 데이터베이스의 데이터가 아니더라도  
디스크(HDD, SSD)에 저장된 파일, 인터넷 상의 데이터, 기타 동적으로 생성되는   
데이터 등 [인 메모리 캐시](https://jaenjoy.tistory.com/20)에 저장되는 데이터는  
매우 다양한다.    
  
※인 메모리 캐시는 모든 데이터를 메모리(RAM)에만 올려놓고 사용하는 데이터베이스의  
일종이다. 일반적인 데이터베이스(RDBMS)는 디스크(HDD, SSD)에 데이터를 영구적으로  
저장해놓고, 필요한 데이터만 메모리에 읽어서 사용한다. 디스크에 접근하지 않고  
메모리로만 모든 처리를 하기 때문에 데이터 저장 및 검색 속도가 매우 빠르지만  
데이터는 딱 메모리 크기(운영체제 사용량 제외)까지만 저장할 수 있다.   
  
전체 데이터는 일반적인 데이터베이스에 저장하고 자주 쓰이는 일부 데이터만   
인 메모리 캐시에 저장한다.  
  
ElasticCache는 두 가지 캐시 엔진을 지원한다.  
- Memcached: 유명한 분산 메모리 캐시 시스템이다.   
- Redis: String, Hash, List, set, Sorted등 다양한 데이터 형식을 제공하는   
키-값(Key-Value) 데이터 저장소이다.   
  
ElasticCache를 이용하면 Memcached 클러스터를 손쉽게 생성하고 확장할 수 있다. 
Memcached 클러스터는 리전의 가용영역(AZ)별로 생성할 수 있다. Memcached 클러스터는   
노드를 계속 추가할 수록 데이터를 저장할 수 있는 공간이 늘어난다. 즉 1.3GB 메모리를  
제공하는 cache.m1.small 캐시 노드를 3개 연결하면 3.9GB를 사용할 수 있다.  
<img src="https://user-images.githubusercontent.com/33191974/156915594-29d57e03-c6cc-4e0e-9b1d-740f84947cfa.png" width="50%" height="50%"/>    
ElastiCache에서 Memcached는 스냅샷 생성과 Read Replica를 지원하지 않는다.   
  
ElasticCache에서는 Redis도 사용할 수 있다. Redis는 Memcached와 달리 클러스터를   
구성할 수 없다. 따라서 노드를 추가한다고 해서 저장할 수 있는 전체 메모리 용량이  
늘어나지는 않는다. 그리고 데이터를 저장할 수 있는 메모리 용량은 각 캐시 노드가  
제공하는 메모리 용량에 한한다.    
<img src="https://user-images.githubusercontent.com/33191974/156915910-9db15697-f48c-4461-b716-b7d530ffe706.png" width="50%" height="50%"/>  
위 그림처럼 ElasticCache에서 Redis는 스냅샷 생성과 Read Replica를 지원한다.  
특히 Read Replica는 마스터 캐시 노드(Primary)에 장애가 발생하면 자동으로 Read  
Replica가 마스터 캐시 노드로 승격되는 Failover 기능이 작동하게 된다. 이후  
새 마스터 캐시 노드에서 쓰기 작업이 진행되게 된다. Read Replica는 Replication  
Group이라는 논리적인 개념이 안에 위치한다. 그리고 Read Replica는 한 리전 안에서  
여러 가용 영역(AZ)에 생성할 수 있다.     
  
Redis 캐시 노드가 제공하는 메모리 용량을 넘어서는 데이터를 저장하기 위해서는   
애플리케이션 레벨에서 데이터를 여러 캐시 노드에 분산하여 저장하는 샤딩(Sharding  
)을 구현해야 한다.  
  
> #### 샤딩   
> 일반적인 데이터베이스와 마찬가지로 인 메모리 캐시도 샤딩을 구현할 수 있다.   
> 데이터 종류별로 서버를 분할하는 방식, 사용자 이름 순, 날짜 순 등으로 분할하는  
> 방식, 해시키를 기준으로 분할하는 방식 등 다양한 방식이 있다.   


































