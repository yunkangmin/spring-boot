### 로그란 무엇일까?
로그는 지수를 다른 방법으로 표현한 것이다.  
예를 들어, 2의 4제곱은 16이라는 것을 알고 있다.  
이 것은 지수방정식 2<sup>4</sup> = 16 으로 나타낼 수 있다.  
  
이제 누군가가 이렇게 물어볼 것이다. 
"2를 몇 제곱해야 16이 되나요?" 정답은 4일 것이다.  
이 것은 로그방정식 log<sub>2</sub>(16) = 4로 나타낼 수 있으며, "2를 밑으로 하는  
16의 로그방정식은 4"라고 읽는다. 
 
### 시간복잡도(Time Complexity)와 공간 복잡도(Space Complexity)
그저 잘 동작하는 자료구조와 알고리즘을 찾는 것이 목적이라면 기능별로 자료구조와 알고리즘을  
하나씩만 알아도 된다.  
하지만 우리는 잘 동작하는 것은 물로이거니와 좋은 성능까지 보장받기를 원한다.  
때문에 우리는 자료구조와 알고리즘을 분석하고 평가할 수 있어야 한다.  
모든 경우에 있어서 항상 우월한 성능을 보이는, 만능 키와 같은 자료구조와 알고리즘은 존재하지 않기 때문이다.  
알고리즘을 평가하는 두 가지 요소는 다음과 같이 정리할 수 있다.  
```
"어떤 알고리즘이 어떠한 상황에서 더 빠르고 또 느리냐?"
"어떤 알고리즘이 어떠한 상황에서 메모리를 적게 쓰고 또 많이 쓰냐?"
```
이렇듯 하나는 '속도'에 관한 것이고 다른 하나는 '메모리의 사용량'에 관한 것인데  
속도는 해당하는 알고리즘의 수행시간 분석결과를 가리켜 '시간 복잡도'라 하고   
메모리 사용량에 대한 분석결과를 가리켜 '공간 복잡도'라 한다.  
  
사실 메모리를 적게 쓰고 속도도 빨라야 최적의 알고리즘이라 할 수 있다.  
그런데 일반적으로 알고리즘을 평가할 때는 메모리의 사용량보다 실행속도에 초점을 둔다.  
대게는 속도에 관심이 더 많고  또 중요한 요소로 판단되기 때문이다.  
물론 특정 알고리즘에 대해서 상대적인 우월성을 입증해야 하는 경우에는 메모리의 사용량도  
함께 고려가 되지만 이미 검증이 끝난 알고리즘의 적용을 고려하는 경우에는 속도에 초점을 두어  
적합성 여부를 판단하게 된다.  
```
"그럼 어떻게 속도를 평가할 수 있나요?"
"연산의 횟루를 셉니다."
"그리고 처리해야 할 데이터의 수n에 대한 연산횟수의 함수 T(n)을 구성합니다."
```
말 그대로 연산의 횟수를 통해서 알고리즘의 빠르기를 판단한다.  
물론 연산의 횟수가 적어야 빠른 알고리즘이다.  
그리고 '데이터의 수 n에 대한 연산횟수의 함수 T(n)을 구성한다.'는 것은 데이터의 수를  
함수에 입력하면 연산의 횟수가 바로 계산이 되는 식을 구성하는 뜻인데  
이렇듯 식을 구성하는 이유는 다음과 같다.  
```
"식을 구성하면 데이터 수의 증가에 따른 연산횟수의 변화 정도를 판단할 수 있다."
```
즉 알고리즘 별 연산횟수를 함수 T(n)의 형태로 구성하면 다음 그림에서 보이는 바와 같이 그래프를  
통해서 데이터 수의 변화에 따른 연산횟수의 변화 정도를 한눈에 파악할 수 있으며 이로 인해서 둘 이상의  
알고리즘을 비교하기가 용이해진다.  
알고리즘의 수행속도 비교  
![image](https://user-images.githubusercontent.com/33191974/128459645-d6658cc5-b962-4290-9902-25488f1131e2.png)

자! 그럼 이번에는 위 그림에서 보이는 것이 동일한 기능을 제공하는 서로 다른 두 알고리즘의 성능을  
비교한 결과라고 가정하고 이 두 알고리즘의 비교결과를 나열해 보겠다.  
```
"오~ 데이터의 수가 적으면 알고리즘 B가 더 빨라"
"근데 데이터의 수가 좀 늘어나면 알고리즘 A가 훨씬 더 빨라지는데!"
```
위의 분석결과를 토대로 다음과 같이 판단할 수도 있다.
```
"데이터의 수가 적은 경우에는 알고리즘 B를 토대로 적용하고, 데이터의 수가 많은 경우에는  
알고리즘 A를 적용해야 한다."
```
뭐 잘못된 판단은 아니다.  
나름 합리적인 판단이고 실제로 이렇게 판단하고 적용하기도 하니 말이다.  
하지만 데이터의 수가 적은 경우, 속도 차가 나봐야 얼마나 나겠는가?  
중요한 것은 데이터의 수가 많아짐에 따른 연산횟수의 증가 정도에 있다.  
```
"그렇게 놓고 보면 알고리즘 A가 훨씬 좋은 알고리즘이네요"
```
그렇다! 알고리즘 A가 훨씬 좋은 알고리즘이다.
```
"그럼 알고리즘 B는 없다고 생각하는 게 좋겠는데요."
```
큰일 날 소리다! 대게 A와 같이 안정적인 성능을 보장하는 알고리즘은 B와 같은 성격의 알고리즘에 비해서  
구현의 난이도가 높은 편이다.  
따라서 데이터의 수가 많지 않고 성능에 덜 민감한 경우라면 구현의 편의를 이유로 B와 같은 알고리즘을 선택  
하기도 한다.  

### 순차탐색(Linear Search) 알고리즘과 시간 복잡도 분석의 핵심요소
그럼 이번에는 '순차 탐색 알고리즘'이라는 매우 간단한 탐색 알고리즘 하나를 여러분에게 소개하고 이를  
대상으로 시간 복잡도를 계산해 보고자 한다.  
먼저 순차 탐색 알고리즘을 적용한 예를 여러분에게 보이겠다.  
  
LinearSearch.c
```c
//순차 탐색 알고리즘이 적용된 함수
int LSearch(int ar[], int len, int target) {
  int i;
  for (i = 0; i < len; i++) {
     if (ar[i] == target)
        return i; //찾은 대상의 인덱스 값 반환
  }
  
  return -1; //찾지 못했음을 의미하는 값 반환
}

int main(void) {
    int arr[] = {3, 5, 2, 4, 9};
    int idx;
    
    idx = LSearch(arr, sizeof(arr)/sizeof(int), 4);
    if (idx == -1)
       printf("탐색 실패 \n");
    else 
       printf("타겟 저장 인덱스: %d \n", idx);
       
    idx = LSearch(arr, sizeof(arr)/sizeof(int), 7);
    if (idx == -1)
       printf("탐색 실패 \n");
    else
       printf("타겟 저장 인덱스: %d \n", idx);
      
    return 0;
}

//실행결과
//타겟 저장 인덱스: 3
//탐색실패
```
위의 코드를 토대로 시간 복잡도를 분석해서 데이터의 수 n에 대한 연산횟수의 함수 T(n)을 구해보자.  
```
"이 알고리즘에서 사용된 연산자는 <, ++, == 이렇게 세 개네요. 애네들이 얼마나 많이 수행되는지를 
분석하면 되는 거죠?"
```
물론 연산 횟수를 세라고 하였으니 모든 연산자를 대상으로 연산횟수를 세어야 할 것 같은 느낌이 들 수 있다.  
그렇다면 다음 질문에 답을 해보자.  
```
"어떠한 연산을 적게 수행하는 탐색 알고리즘이 좋은 탐색 알고리즘이겠는가?"
```
값의 동등을 비교하는 == 연산을 적게 수행하는 탐색 알고리즘이 좋은 탐색 알고리즘이다.  
즉, 탐색 알고리즘에서의 핵심은 동등비교를 하는 비교연산에 있다.  
비교 연산의 수행횟수가 줄어들면 < 연산과 ++연산의 수행횟수도 줄어들고 비교연산의 수행횟수가  
늘어나면 < 연산과 ++ 연산의 수행횟수도 늘어나기 때문이다.  
정리하면 다른 연산들은 == 연산에 의존적이다.  
따라서 우리는 == 연산의 횟수를 대상으로 시간 복잡도를 분석하면 된다.  
이렇듯 알고리즘의 시간 복잡도를 계산하기 위해서는 핵심이 되는 연산이 무엇인지 잘 판단해야 한다.  
그리고 그 연산을 중심으로 시간 복잡도를 계산해야 한다.  
```
"알고리즘마다 핵심이 되는 연산을 찾는 것도 쉬운 일은 아닌 것 같은데요"
```
사실 객과적인 근거를 마련해서 알고리즘의 성능을 분석하는 것 자체가 쉬운 일이 아니다.  
그러나 흔히 하는 일은 아니니 부담을 갖지는 말자.  
필자와 함께 알고리즘의 성능을 한 두 차례 분석해 봤다는 데에도 의미가 있으니 말이다.  
그럼 다시 본론으로 돌아와서 순차 탐색 알고리즘의 비교연산횟수를 계산해보자.  
그런데 순차 탐색 알고리즘을 봐서 알겠지만, 운이 좋아서 찾고가 하는 값이 배열의 맨 앞에  
저장되어 있으면 비교연산의 수행횟수는 1이 되고, 운이 없어서 찾고자 하는 값이 배열의 맨 마지막에  
저장되어 있거나 찾고자 하는 값이 아예 저장되어 있지 않으면 비교연산의 수행횟수는 n이 된다.  
(탐색의 대상이 되는 요소의 수가 n이라고 가정), 이렇듯 모든 알고리즘에는 가장 행복한 경우와  
가장 우울한 경우가 각각 존재하며, 이를 전문용어로 '최선의 겨우(best case)' 그리고  
'최악의 경우(worst case)'라 한다.  
그런데 알고리즘을 평가하는데 있어서 '최선의 경우'는 관심대상이 아니다.  
어떤한 알고리즘이건 간에 최선의 경우는 대부분 만족할만한 결과를 보이기 때문이다. 
즉, 다음과 같이 말도 안 되는 고민은 하지 않는다.  
```
"이 알고리즘은 최선의 경우 두 번의 연산을 진행하는데 저 알고리즘은 최선의 경우 다섯 번의 연산을 하네.
이거 속도 차 무지 나는구만!"
```
반면 '알고리즘의 수행속도 비교' 그래프를 통해서도 알 수 있듯이 데이터의 수가 많아지면 '최악의 경우'에  
수행하게 되는 연산의 횟수는 알고리즘 별로 큰 차이를 보인다.  
따라서 알고리즘의 성능을 판단하는데 있어서 중요한 것은 '최악의 경우'이다.  
```
"최악도 최선도 아닌 평균적인 경우를 따져야 하는 것 아닌가요? 그게 더 현실적인 것 같은데요."
```
정확한 지적이다! 실제로 '평균적인 경우(average case)'는 시간 복잡도를 평가하는 정보로 의미를 지닌다.  
하지만 문제는 이를 계산하는 것이 쉽지 않다는데 있다.  
이를 계산하기 위해서는 다양한 이론이 적용되어야 하고, 분석에 필요한 여러가지 시나리오와 데이터를 현실적  
이고 합리적으로 구성해야 하는데, 이는 쉽지 않은 일이다.  
간단히 말해서, 기본이 되는 다음 질문에 답을 하기조차 쉽지가 않다.  
```
"무엇이 평균적인 상황이냐?"
```
때문에 '평균적인 경우'라고 주장하기 위해서는 다양한 자료들이 광범위하게 수집되어야 한다.  
결국 일반적인 알고리즘의 평가에는 논란의 소지가 거의 없는 '최악의 경우(worst case)'가 선택될 수  
밖에 없다.  
참고로 위에서 보인 순차 탐색 알고리즘의 '평균적인 경우'를 계산하는 것은 어렵지는 않다.  
그래서 순차 탐색 알고리즘의 '평균적인 경우'를 계산해볼 것이다.  
하지만 알고리즘이 이보다 조금만 더 복잡해져도 '평균적인 경우'를 계산하는 것은 쉽지 않은 일이다.  

### 순차 탐색 알고리즘의 시간 복잡도 계산하기1: 최악의 경우(worst case)
그럼 순차 탐색 알고리즘의 시간 복잡도를 계산해보겠다.  
그런데 계산할 것이 사실상 없다.  
이 알고리즘의 흐름을 소스코드상에서 이해했다면 다음 사실을 바로 파악할 수 있기 때문이다.  
```
"데이터의 수가 n개일 때, 최악의 경우에 해당하는 연산횟수는 (비교연산의 횟수는)n이다."
```
따라서 순차 탐색 알고리즘의 '데이터 수 n에 대한 연산횟수의 함수 T(n)' 다음과 같다.  
물론 이는 최악의 경우를 대상으로 정의한 함수이다.  
```
T(n) = n //최악의 경우를 대상으로 정의한 함수 T(n)
```
































